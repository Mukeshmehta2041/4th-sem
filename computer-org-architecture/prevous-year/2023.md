
1.  
a) Explain basic principles of computer architecture.  
b) What is Multiprocessing? Discuss types of data transfer in detail.

2.  
a) Explain the following terms  
 i) Stack organization  
 ii) Bus structure and addressing modes  
 iii) Fetch and execution cycle

3.  
a) Write Booth’s algorithm. Also explain floating point arithmetic operation.  
b) Describe signal addition and subtraction in detail.

4.  
a) Elaborate following with examples:  
 i) Serial and parallel data transfer  
 ii) Synchronous and asynchronous modes of data  
b) Write notes on following:  
 i) Direct memory access  
 ii) PCI Bus and SCSI Bus

5.  
a) Compare following  
 i) Main memory and secondary memory  
 ii) Cache memory and Virtual memory  
b) Describe replacement algorithm and write steps to improve cache performance.

6.  
a) Explain characteristics and structure of multiprocessor.  
b) What is concept of pipelining? Differentiate vector processing and array processing.

7.  
a) Describe following in brief  
 i) LRU algorithm  
 ii) Tools compliment representation  
 iii) Memory management hardware  
b) What is inter-processor communication and synchronization? Also describe inter-processor arbitration.

8.  
a) Discuss multicore processor in detail.  
b) Write short notes on following:  
 i) Semiconductor memories  
 ii) Hardwired control unit  
 iii) RISC and CISC  
 iv) Micro instruction formats

---

### **Solutions**

**1.**
**a) Explain basic principles of computer architecture.**

Computer architecture describes the fundamental design and operational structure of a computer system. Key principles include:

1.  **Von Neumann Architecture (Stored-Program Concept):** This is the core principle of most modern computers. It states that both program instructions and the data they operate on are stored together in the same memory. The CPU fetches instructions from memory one after another and executes them.
2.  **Functional Units:** A computer system is composed of three main units:
    *   **Central Processing Unit (CPU):** The brain of the computer, which contains the Arithmetic Logic Unit (ALU) for calculations and the Control Unit (CU) to direct operations.
    *   **Memory Unit:** Stores instructions and data.
    *   **Input/Output (I/O) Devices:** Allow the computer to interact with the outside world (e.g., keyboard, monitor).
3.  **Instruction Set Architecture (ISA):** This is the interface between the hardware and the software. It defines the set of instructions the CPU can execute, the data types, registers, and memory addressing modes.
4.  **Memory Hierarchy:** To balance speed, cost, and size, memory is organized in a hierarchy:
    *   **Registers:** Fastest, smallest, inside the CPU.
    *   **Cache:** Fast memory close to the CPU.
    *   **Main Memory (RAM):** The primary working memory.
    *   **Secondary Storage:** Slower, larger, non-volatile storage (e.g., SSD, HDD).
5.  **Parallelism:** Modern architectures use parallelism to improve performance, for example:
    *   **Pipelining:** Overlapping the steps of different instructions.
    *   **Multiprocessing:** Using multiple CPUs or cores.

**b) What is Multiprocessing? Discuss types of data transfer in detail.**

**Multiprocessing** is the use of two or more central processing units (CPUs) or processor cores within a single computer system. These processors share the system's main memory, I/O devices, and other peripherals. The primary goal is to increase system performance (throughput) and reliability.

*   **Symmetric Multiprocessing (SMP):** All processors are peers; any processor can run any task, including the operating system. This is the most common type in modern multi-core PCs.
*   **Asymmetric Multiprocessing (ASMP):** One processor acts as the "master" and controls the system, while other processors are "slaves" and perform specific tasks assigned by the master.

**Types of Data Transfer:**

| Feature                 | Serial Transfer                                                              | Parallel Transfer                                                                 |
| ----------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **Data Transmission**   | Bits are sent one after another over a **single wire**.                      | All bits of a word are sent simultaneously on **multiple dedicated wires**.       |
| **Speed**               | **Slower**. Only one bit transferred per clock cycle.                        | **Faster** (in theory). An entire word transferred in one clock cycle.            |
| **Implementation**      | **Simple and Cheap**. Ideal for long distances.                              | **Complex and Expensive**. Prone to "skew" (bits arriving at different times) over long distances. |
| **Examples**            | USB, SATA, Ethernet.                                                         | Older printer ports, internal CPU buses.                                          |

| Feature           | Synchronous Transfer                                                                  | Asynchronous Transfer                                                                  |
| ----------------- | ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| **Timing**        | Governed by a **common clock signal** shared by sender and receiver.                  | **Not governed by a common clock**. Uses special control signals for coordination.   |
| **Mechanism**     | Events happen at specific points in the clock cycle.                                  | Uses a **handshaking** protocol (e.g., "data ready," "data acknowledged").           |
| **Usage**         | Internal CPU buses, memory communication (SDRAM).                                     | Peripherals like keyboards, printers (USB, RS-232).                                    |

**2.**
**a) Explain the following terms**
**i) Stack organization**
A stack is a memory unit with a **Last-In, First-Out (LIFO)** access mechanism. Data can only be added (pushed) or removed (popped) from the top of the stack. A **Stack Pointer (SP)** register always holds the address of the top element.
*   **PUSH operation:** The SP is decremented, and a new item is placed at the address it points to.
*   **POP operation:** The item at the SP's address is retrieved, and the SP is incremented.
Stacks are crucial for managing function calls (storing return addresses and local variables) and evaluating arithmetic expressions in some architectures.

**ii) Bus structure and addressing modes**
*   **Bus Structure:** A bus is a communication pathway connecting two or more components. The main **System Bus** has three parts:
    1.  **Address Bus:** Unidirectional. Carries the memory address that the CPU wants to read from or write to.
    2.  **Data Bus:** Bidirectional. Carries the actual data between the CPU, memory, and I/O devices.
    3.  **Control Bus:** Carries control signals and timing information from the Control Unit (e.g., Memory Read/Write, Interrupt Request).
*   **Addressing Modes:** These are the different ways an instruction can specify the location of its operand(s).
    *   **Immediate:** The operand is part of the instruction itself.
    *   **Direct:** The instruction contains the memory address of the operand.
    *   **Indirect:** The instruction contains a memory address that points to the *address* of the operand.
    *   **Register:** The operand is in a CPU register.
    *   **Indexed:** The operand's address is calculated by adding an offset (from the instruction) to the value in an index register.

**iii) Fetch and execution cycle**
This is the **Instruction Cycle**, the fundamental process by which a CPU executes an instruction.
1.  **Fetch:** The CPU fetches the next instruction from the memory location pointed to by the **Program Counter (PC)**. The instruction is loaded into the **Instruction Register (IR)**. The PC is then incremented.
2.  **Decode:** The **Control Unit (CU)** decodes the instruction in the IR to determine what operation to perform.
3.  **Execute:** The CU sends control signals to the appropriate hardware (e.g., the ALU) to perform the operation. This may involve fetching operands from memory or registers, performing a calculation, and storing the result.
This cycle repeats for every instruction in a program.

**3.**
**a) Write Booth’s algorithm. Also explain floating point arithmetic operation.**
*   **Booth's Algorithm:** See solution 2.b from the 2024 paper for a detailed flowchart and example. It is an efficient algorithm for multiplying signed 2's complement numbers by examining pairs of bits in the multiplier.
*   **Floating-Point Arithmetic:** See solution 3.a from the 2024 paper. The key steps are:
    *   **Addition/Subtraction:** Align exponents by shifting one mantissa, then add/subtract the mantissas, and finally normalize the result.
    *   **Multiplication:** Multiply mantissas and add exponents, then normalize.
    *   **Division:** Divide mantissas and subtract exponents, then normalize.

**b) Describe signal addition and subtraction in detail.**
This refers to the addition and subtraction of **signed binary numbers**, which is almost always done using **2's complement representation**.

**Addition:**
1.  Represent both numbers in 2's complement form (using a fixed number of bits, e.g., 8-bits).
2.  Perform a standard binary addition on the two numbers.
3.  Ignore any carry-out from the most significant bit (MSB) position. The result is in 2's complement form.
    *   *Example (5 + (-3)):* `0101 + 1101 = (1)0010`. Ignore carry. Result is `0010` (+2).

**Subtraction (A - B):**
This is performed as `A + (-B)`.
1.  Find the 2's complement of the number being subtracted (B).
2.  Add the result to A using the addition rules above.
    *   *Example ((-2) - 3) -> (-2) + (-3):* `1110 + 1101 = (1)1011`. Ignore carry. Result is `1011` (-5).

**Overflow:**
An overflow occurs when the result of an operation is too large to be represented in the available number of bits. In signed 2's complement arithmetic, overflow can be detected if:
*   The sum of two **positive** numbers yields a **negative** result.
*   The sum of two **negative** numbers yields a **positive** result.

**4.**
**a) Elaborate following with examples:**
*   **i) Serial and parallel data transfer:** See solution 4.a from the 2024 paper.
*   **ii) Synchronous and asynchronous modes of data:** See solution 5.a from the 2024 paper.

**b) Write notes on following:**
**i) Direct memory access (DMA)**
See solution 4.b from the 2024 paper. DMA is a mechanism that allows I/O devices to transfer data directly to or from main memory without involving the CPU. The CPU sets up a **DMA Controller (DMAC)** with the source/destination addresses and the amount of data. The DMAC then manages the transfer, freeing the CPU to perform other tasks and significantly improving system performance for bulk data transfers.

**ii) PCI Bus and SCSI Bus**
*   **PCI (Peripheral Component Interconnect) Bus:** A high-speed local bus standard for connecting hardware devices (like sound cards, network cards, graphics cards) to a computer's motherboard. It standardized the connection mechanism and supported "Plug and Play," which allowed the OS to automatically configure devices. It has largely been replaced by PCIe (PCI Express), which is a faster, serial version.
*   **SCSI (Small Computer System Interface) Bus:** A set of standards for connecting and transferring data between computers and peripheral devices, primarily high-performance storage like hard drives and tape drives. A single SCSI bus can host multiple devices (e.g., 7 or 15) in a daisy-chain configuration. It was known for its robustness and performance, and is still used in some enterprise servers, though it has been largely superseded by SATA and SAS.

**5.**
**a) Compare following**
**i) Main memory and secondary memory**

| Feature           | Main Memory (RAM)                               | Secondary Memory (Storage)                          |
| ----------------- | ----------------------------------------------- | --------------------------------------------------- |
| **Technology**    | Semiconductor chips (DRAM)                      | Magnetic disks (HDD), Flash memory (SSD)            |
| **Volatility**    | **Volatile** (loses data when power is off)     | **Non-Volatile** (retains data without power)       |
| **Speed**         | Very fast access time (nanoseconds)             | Much slower access time (microseconds to milliseconds) |
| **Capacity**      | Smaller capacity (Gigabytes)                    | Larger capacity (Gigabytes to Terabytes)            |
| **Cost**          | Higher cost per bit                             | Lower cost per bit                                  |
| **CPU Access**    | Accessed **directly** by the CPU                | Accessed via I/O routines; data must be moved to main memory for CPU access. |
| **Purpose**       | Holds currently running programs and their data. | Long-term, permanent storage of files and programs. |

**ii) Cache memory and Virtual memory**

| Feature            | Cache Memory                                               | Virtual Memory                                                              |
| ------------------ | ---------------------------------------------------------- | --------------------------------------------------------------------------- |
| **Purpose**        | To **speed up** access to data in main memory (RAM).       | To **increase the apparent size** of main memory.                           |
| **Implementation** | A **hardware**-based solution. A small, fast SRAM memory.  | A **software and hardware** technique managed by the OS and MMU.            |
| **Mechanism**      | Stores copies of frequently used data from RAM.            | Uses part of the hard disk or SSD as an extension of RAM.                   |
| **Size**           | Small (Kilobytes to Megabytes).                            | Large (can be many Gigabytes).                                              |
| **Speed**          | Very fast.                                                 | Very slow (limited by disk speed).                                          |
| **Managed By**     | The hardware Cache Controller.                             | The Operating System.                                                       |

**b) Describe replacement algorithm and write steps to improve cache performance.**

**Replacement Algorithms**
When a cache is full and a new block of data needs to be brought in, a replacement algorithm decides which existing block to evict.
*   **LRU (Least Recently Used):** This algorithm replaces the block that has not been accessed for the longest period of time. It's effective because it works well with the principle of temporal locality, but it is complex to implement in hardware.
*   **FIFO (First-In, First-Out):** This algorithm replaces the block that has been in the cache the longest, regardless of how recently it was used. It is very simple to implement but can perform poorly, as it might evict a frequently used block.

**Steps to Improve Cache Performance:**
The goal is to maximize the number of cache hits and minimize the impact of a miss.
1.  **Reduce the Miss Rate:**
    *   **Increase Cache Size:** A larger cache can hold more data, reducing capacity misses.
    *   **Increase Associativity:** Higher associativity (e.g., changing from direct-mapped to 2-way or 4-way set-associative) reduces conflict misses.
    *   **Use a Better Replacement Algorithm:** An algorithm like LRU is generally better than random or FIFO.
2.  **Reduce the Miss Penalty** (the time it takes to get data after a miss):
    *   **Use a Multilevel Cache:** Having L1, L2, and sometimes L3 caches means a miss in L1 might be a hit in the slightly slower but larger L2, which is much faster than going to main memory.
    *   **Use a Faster Bus:** A faster bus between the cache and main memory reduces data transfer time.
3.  **Reduce the Hit Time** (the time to access data that is in the cache):
    *   **Keep the Cache Small and Simple:** A smaller, less associative cache has less complex circuitry, leading to a faster hit time. This is a direct trade-off with reducing the miss rate.

**6.**
**a) Explain characteristics and structure of multiprocessor.**

See solution 1.b for a definition.
**Characteristics:**
*   **Multiple CPUs/Cores:** Contains two or more processing units.
*   **Shared Resources:** The processors share main memory and I/O peripherals.
*   **Increased Throughput:** Multiple tasks can be executed in parallel, improving overall performance.
*   **Increased Reliability:** If one processor fails, the others can often continue to operate (fault tolerance).
*   **Single Operating System:** The entire system is managed by a single instance of an operating system.

**Structure:**
The structure is mainly defined by how memory is shared:
*   **Tightly-Coupled (Shared Memory):** All processors share a single, central memory space with a uniform access time (**UMA - Uniform Memory Access**). Alternatively, each processor may have its own local memory but can also access the memory of other processors, leading to different access times (**NUMA - Non-Uniform Memory Access**).
*   **Loosely-Coupled (Distributed Memory):** Each processor has its own private local memory. The processors are connected by an interconnection network and communicate by passing messages. This is the model used in large computer clusters.

**b) What is concept of pipelining? Differentiate vector processing and array processing.**

**Concept of Pipelining:**
Pipelining is a technique where multiple instructions are overlapped in execution. The instruction cycle is broken down into a series of stages (e.g., Fetch, Decode, Execute, Write-back). Each stage is handled by a different piece of hardware, which works in parallel with the other stages. It's like an assembly line for instructions: while one instruction is being executed, the next one is being decoded, and the one after that is being fetched. Pipelining doesn't reduce the time for a single instruction to complete, but it dramatically increases the **instruction throughput** (the number of instructions completed per unit of time).

**Vector Processing vs. Array Processing:**
Both are forms of **SIMD (Single Instruction, Multiple Data)** parallel processing, but they have different hardware implementations.

| Feature               | Vector Processing                                                                 | Array Processing                                                                       |
| --------------------- | --------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| **Hardware**          | A **single processor** with specialized, heavily pipelined functional units.      | An array of **multiple, identical Processing Elements (PEs)**.                         |
| **Instruction Type**  | Has special **vector instructions** that operate on entire vectors (1D arrays) of data. E.g., `VADD V1, V2, V3`. | A single control unit broadcasts a conventional instruction (e.g., `ADD`) to all PEs. |
| **Data Storage**      | Data is stored in large **vector registers** within the processor.                | Each PE has its own small, local memory.                                               |
| **Execution**         | A single instruction pipeline processes vector elements sequentially at a high rate. | All PEs execute the same instruction in lockstep, each on its own data element.        |
| **Analogy**           | A single, highly efficient assembly line that processes a long stream of parts.     | A large team of workers, where every worker does the exact same thing at the same time. |

**7.**
**a) Describe following in brief**
**i) LRU algorithm**
Least Recently Used (LRU) is a cache replacement algorithm that discards the item that has been used the least recently. The logic is that if a piece of data hasn't been used in a while, it's unlikely to be used again soon (based on temporal locality). It offers a good hit rate but is more complex to implement than simpler algorithms like FIFO.

**ii) 2's complement representation**
This is the standard method for representing signed integers on computers. For a given number of bits (n):
*   A positive number is represented by its normal binary value. The most significant bit (MSB) is 0.
*   A negative number `-X` is found by taking the binary value of `X`, inverting all the bits, and then adding 1. The MSB of a negative number is 1.
This system makes signed arithmetic (addition and subtraction) straightforward, as standard binary addition rules apply.

**iii) Memory management hardware**
The **Memory Management Unit (MMU)** is a hardware component responsible for handling all memory-related operations. Its key functions are:
*   **Virtual to Physical Address Translation:** It translates the logical addresses generated by the CPU into the physical addresses of main memory, typically using page tables.
*   **Memory Protection:** It enforces access rights (e.g., read-only, execute-only) for different memory segments, preventing one process from interfering with another.
*   **Cache Control:** It helps manage the system's cache.
The **Translation Lookaside Buffer (TLB)** is a crucial part of the MMU; it's a small cache that stores recent address translations to speed up the translation process.

**b) What is inter-processor communication and synchronization? Also describe inter-processor arbitration.**

*   **Inter-processor Communication:** This is the way processors in a multiprocessor system exchange data and information. In **shared memory systems**, this happens through shared variables in the common memory. In **distributed memory systems**, it is done by explicitly sending and receiving messages over the interconnection network.
*   **Synchronization:** This refers to mechanisms that control the sequence of events in different processors to ensure data consistency and avoid race conditions. For example, a **mutex** or **lock** can be used to ensure that only one processor can access a critical section of shared data at a time.
*   **Inter-processor Arbitration:** This is the process of resolving conflicts when multiple processors request access to a shared resource (like the system bus) at the same time. The **arbitration logic** decides which processor gets access.
    *   **Serial (Daisy Chain) Arbitration:** A simple method where priority is based on the processor's position in a chain.
    *   **Parallel Arbitration:** Each processor has a dedicated request line, and an arbiter logic circuit decides priority.

**8.**
**a) Discuss multicore processor in detail.**
A **multicore processor** is a single integrated circuit (a single chip) that contains two or more independent processing units, called "cores." Each core can read and execute program instructions as if it were its own CPU.

*   **Structure:** From the perspective of the operating system, each core appears as a separate CPU. The cores on a single chip are tightly integrated. They typically have their own private, fast L1 cache, while often sharing a larger L2 or L3 cache and the main memory interface.
*   **Multicore vs. Multiprocessor:** A traditional multiprocessor system has multiple separate CPU chips on the motherboard. A multicore system has multiple cores on a single chip. Multicore is more power-efficient and allows for faster communication between cores since they are on the same piece of silicon.
*   **Advantages:**
    *   **Increased Performance:** Multiple tasks can be executed in true parallel, significantly improving throughput for multithreaded applications.
    *   **Power Efficiency:** Increasing performance by adding cores is more power-efficient than trying to increase the clock speed of a single core, which generates much more heat.
*   **Challenges:** The main challenge is that software must be written as parallel programs (multithreaded) to take full advantage of the hardware. The "free lunch" of automatically faster software with each new processor generation is over. Another challenge is maintaining **cache coherency**—ensuring that all cores have a consistent view of data that might be shared in their caches.

**b) Write short notes on following:**
**i) Semiconductor memories**
These are memory devices built using semiconductor-based integrated circuits. They are the primary memory in most computers. The two main types are:
*   **RAM (Random-Access Memory):** Volatile memory.
    *   **SRAM (Static RAM):** Very fast, expensive, and used for cache memory. It holds its data as long as power is supplied without needing to be refreshed.
    *   **DRAM (Dynamic RAM):** Slower and cheaper than SRAM, used for main memory. It stores data in capacitors that lose their charge, so it must be constantly refreshed.
*   **ROM (Read-Only Memory):** Non-volatile memory, used for storing firmware like the BIOS. Variants include PROM, EPROM, and EEPROM/Flash memory.

**ii) Hardwired control unit**
This is one way to implement the CPU's Control Unit. The CU's logic is built from fixed logic circuits (like AND, OR, NOT gates) and flip-flops. The input to this circuit is the instruction register, and the output is the set of control signals that operate the rest of the CPU.
*   **Pros:** Very fast because signals are generated by dedicated combinational logic.
*   **Cons:** Inflexible. If the instruction set needs to be changed or a bug is found, the hardware itself must be redesigned. It is very complex to design for complex instruction sets.

**iii) RISC and CISC**

| Feature               | CISC (Complex Instruction Set Computer)                                   | RISC (Reduced Instruction Set Computer)                                   |
| --------------------- | ------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **Philosophy**        | Aim to complete a task in as few lines of assembly code as possible.      | Aims to have simple instructions that can be executed quickly (one per clock cycle). |
| **Instruction Set**   | Large number of complex instructions.                                     | Small number of simple, optimized instructions.                           |
| **Addressing Modes**  | Many complex addressing modes.                                            | Few simple addressing modes.                                              |
| **Hardware**          | Complex hardware, often using a microprogrammed control unit.             | Simple hardware, often using a hardwired control unit.                    |
| **Pipelining**        | More difficult to pipeline effectively.                                   | Easy to pipeline.                                                         |
| **Examples**          | Intel x86, AMD x86-64.                                                    | ARM, MIPS, RISC-V.                                                        |

**iv) Micro instruction formats**
In a microprogrammed control unit, the logic is stored as microinstructions in a control memory. The format of these microinstructions can be:
*   **Horizontal:** The microinstruction is very wide. Each bit in the instruction directly corresponds to a control signal. This is fast and allows for a high degree of parallelism (many control signals can be activated at once), but it uses a lot of memory.
*   **Vertical:** The microinstruction is narrow. Control signals are encoded into fields. For example, a 3-bit field could specify one of eight possible ALU operations. These encoded fields must be passed through a decoder to generate the final control signals. This is more memory-efficient but can be slower due to the decoding step.
A **hybrid** approach is often used, combining the best features of both.

